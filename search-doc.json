[{"title":"Hello","type":0,"sectionRef":"#","url":"blog/hello-world","content":"Welcome to this blog. This blog is created with Docusaurus 2 alpha. This is a test post. A whole bunch of other information.","keywords":""},{"title":"Hola","type":0,"sectionRef":"#","url":"blog/hola","content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet","keywords":""},{"title":"Introduction","type":0,"sectionRef":"#","url":"docs/","content":"Welcome to Leaf's Documentation! Food and Agriculture developers use Leaf's API to access clean, standardized, and aggregated Farm data from all major sources. These quickstart tutorials are written to help you start accessing farm data quickly, easily, and securely. We have implementation examples in cURL, NodeJS and Python! tip Please don't hesitate to contact us to scheudle a demo, ask a question, request sample data, or suggest a feature!","keywords":""},{"title":"Welcome","type":0,"sectionRef":"#","url":"blog/welcome","content":"Blog features are powered by the blog plugin. Simply add files to the blog directory. It supports tags as well! Delete the whole directory if you don't want the blog features. As simple as that!","keywords":""},{"title":"Authentication","type":0,"sectionRef":"#","url":"docs/001-authentication","content":"To access our API, you just have to register using this link. After confirming your email, you will be able to request a JWT through this endpoint: Copy https://a.agrigate.io/api/authenticate You will receive an access token as response. All set! Include this token in your API calls and you will have access to Leaf's API. The token lasts for 8h. After that, just make the same request to the same endpoint and you will get a new access token. The examples below show you how to login. JavaScriptPythonBash Copy const axios =require('axios') const endpoint ='https://a.agrigate.io/api/authenticate' const data ={ username:'username', password:'password'} axios.post(endpoint,{ data }) .then(res=>console.log(res.data)) .catch(console.error) This request will return your access token to Leaf's API: Copy { \"id_token\":\"YOUR_TOKEN\" }","keywords":""},{"title":"Operations","type":0,"sectionRef":"#","url":"docs/301-operations-guide","content":"","keywords":""},{"title":"Overview","type":1,"pageTitle":"Operations","url":"docs/301-operations-guide#overview","content":"Leaf's Operation Data API returns aggregated, cleaned, and standardized data from all major machine data brands in a simple JSON response. This tutorial will walk through how to create a Leaf user, securely authenticate with their chosen platforms, and receive auto-updating data from all of them with a single request. We also provide a quickstart Postman collection so you can follow along easily. To make calls to Leaf's API, you will need a Leaf account. If you don't have one yet, please create your Leaf account and get your token. You can integrate with many different companies, and you only have to do it once for each user. To connect, you just choose the company you wish to connect to and follow these 3 steps: Get the authentication URL of company you want to connect toGet yours and your user's tokensAdd credentials to Leaf Now you can opt to connect to more companies or Create a Leaf User and attach these credentials, so that Leaf can represent your user internally and you can query specifically for them and their data. All set! Leaf automatically detects and starts processing new files. You can access in \"Get Operation Files\". "},{"title":"Roadmap","type":1,"pageTitle":"Operations","url":"docs/301-operations-guide#roadmap","content":"Today, you can to connect to these companies: John Deere (Medium)Climate FieldView (Medium)CNHiTrimble Coming in the third quarter of 2020: RavenAGCO Coming in the fourth quarter of 2020: AgLeaderStara "},{"title":"John Deere","type":1,"pageTitle":"Operations","url":"docs/301-operations-guide#john-deere","content":"This section will show you how you can integrate Leaf's API with you John Deere account and start using our operations service. Grab our quickstartPostman collection and follow along! 1. Get John Deere auth URL# In Step 1 we will be generating tokens from John Deere. The goal In step 2 is we will get our John Deere token_id and token_secret. Token Verifier# In step 1 we will get a temporary \"token verifier\" from John Deere that confirms an user’s authentication of your application to access their John Deere data and generate credentials. We get that verifier by going through their authentication flow (OAuth2). Before generating the authentication URL, please: Update current value of jd_client_key to your app's client key on John DeereUpdate current value of jd_client_secret to your app's client secret on John DeereUpdate current value of jd_callback_url to your app's callback_url on John Deere Then, to generate the authentication URL your application will send to your user so they can authorize access to their account files you can use the included step 2 in the Postman Collection. Change client_key and client_ secretvariables to yours received from John Deere when you created an app on your developer account with them and redirect_uri to a uri the \"token verifier\" will be sent after the user authorizes your application. Hit Send. Redirect your user to the url included in the response. They will authenticate and be redirected to the redirect_url. Copy the entire url you were redirected to. It looks like: Copy https://leafagriculture.com.br/?oauth_token=TOKEN&oauth_verifier=CODE Paste it in the environment variable jd_response_url. 2. Get John Deere Tokens# After updating the jd_response_url in Postman you can submit your credentials and receive your tokens. Hit Send token_id and token_secret_key will be automatically transferred tojd_token_id and jd_token_secret environment variables and will be used in the next step. 3. Add John Deere credentials# Now we can create a Developer-User pair credentials ID that will allow you to access your user’s John Deere data. We first add the John Deere credentials to Leaf API. Hit Send All the info needed has already been filled automatically in Step 2. An id for the credentials you just created will be returned. This id will be automatically transferred to the value of jd_credentials_id to be used in the next step. "},{"title":"Climate Field View","type":1,"pageTitle":"Operations","url":"docs/301-operations-guide#climate-field-view","content":"Grab our quickstart Postman collection and follow along! 1. Get Climate Field View auth URL# We will be generating a url to redirect your user to authenticate with Climate. Update environment variables cfv_client_id and cfv_client_secret to your Climate Field View developer account credentials. Update environment variable cfv_redirect_url to your application's backend Redirect your user to the script's output url. They will authenticate and be redirected to the redirect_uri. A code will be sent to that cfv_redirect_url. We will need this code Step 2. Copy the code value. note: this code expires after 1 minute. Paste code value to environment variable cfv_code 2. Get Climate Field View tokens# Hit \"Send\" A lot of information will be returned. The important ones are access_tokenand refresh_token. These will be automatically transferred tocfv_access_token and cfv_refresh_token environment variables and will be used in the next step. 3. Add Climate Field View credentials# Now we can create a Developer-User pair credentials ID that will allow you to access your user’s Climate data. We first add the Climate credentials to Leaf API, to do that: Hit \"Send\" An id for the credentials you just created will be returned. This id will be automatically transferred to the value of cfv_credentials_id to be used in the next step. "},{"title":"Leaf User","type":1,"pageTitle":"Operations","url":"docs/301-operations-guide#leaf-user","content":"Create Leaf User# Now we have to attach credentials to a Leaf User. To do so, we can create a Leaf user and attach our John Deere and/or Climate Field View credentials via the credentials id. We can also attach credentials from other companies to this same user to query all available data by Grower/Farm/Field regardless of brand. Update (optional) fields \"address\", \"email\", \"name\" and \"phone\" with your user's information. We have automatically included our jd_credentials_id to this call and attached it to this user. Hit \"Send\" Along with other information returned, there is an \"id\". This \"id\" is theleaf_user_id that will be used in the next (final) Step to query and access files. Update Leaf User# To update a Leaf User, let's say to add another provider credentials or change the user's address, we can use this PUT request. Since this method overwrites, remember to send all the user's information along with the information you want to add or update. For example, if you want to add John Deere credentials to a user that already has ClimateFieldView credentials, remember to specify both credentials ids. Get specific Leaf User# Get specific Leaf User With this endpoint you can query all information on a specific Leaf User, such as their address, email, credentials, etc. To do so, update the value of the environment variable leaf_user_id to the Leaf User id you want to query. Gel all Leaf Users# Get all Leaf Users With this endpoint you can query all information on all your Leaf Users, such as their address, email, credentials, etc. Just hit 'send'. "},{"title":"Query Operations by Field","type":1,"pageTitle":"Operations","url":"docs/301-operations-guide#query-operations-by-field","content":"To query all operations that happened in a specific field (step 2), we first need to create that field (step 1). Then, Leaf will automatically detect operations of that field based on the operations' and on the field's coordinates. This process usually takes about 30 minutes. 1. Create Field# Here we need to specify a leafUserId (that will be the Leaf User owner of that field), a externalId (that will be the name we give to the field) and the geojson geometry of the field (location). After creating the field we can query it (step 2) 2. Get operations' ids by Field# To query all operations that happened in a specific field, just update the environment variable field_external_id to the field id you want to query files. "},{"title":"Merge Operation Files","type":1,"pageTitle":"Operations","url":"docs/301-operations-guide#merge-operation-files","content":"1. Merge files# Merging files with Leaf is a very simple process. You just have to list, in the request json body, the ids of the files you want to merge. Make sure the operations are of the same type (APPLIED or HARVESTED or PLANTED), so the results are consistent. After that, just hit \"send\" and an id for that merged file will be returned. You can query that file as any other. It will be listed when you query for all files and can also be queried specifically by its id 2. Query & access specific file# You can query a merged file as any other. It will be listed when you query for all files and can also be queried specifically by its id. So this request is the same as seen on \"Get Operation Files\". You just have to update the environment variable \"id\" to the id of the merged file. Keep in mind that merging files is processing-heavy and may take about 20 minutes to finish. "},{"title":"Converters","type":0,"sectionRef":"#","url":"docs/500-converter","content":"","keywords":""},{"title":"File Conversion","type":1,"pageTitle":"Converters","url":"docs/500-converter#file-conversion","content":"If you want to allow users to upload machine files directly to your dashboard or to convert recommendations to a machine-readable format or have another use that requires file conversion, these converters will help. Roadmap Today, you have the option to use these converters: Shapefile -> ISOXMLCNHI -> GeoJSONTrimble -> GeoJSONShapefile -> GeoJSONGeoJSON -> Shapefile "},{"title":"Shapefile -> ISOXML","type":1,"pageTitle":"Converters","url":"docs/500-converter#shapefile---isoxml","content":"Send this along with your zipped shapefile PythonBashJavaScript Copy var request = require('request'); var headers = { 'Authorization': 'Bearer YOUR_TOKEN' }; var options = { url: 'https://a.agrigate.io/quickstart/api/files/shapefile/isoxml', method: 'POST', headers: headers }; function callback(error, response, body) { if (!error && response.statusCode == 200) { console.log(body); } } request(options, callback); Returns status 200 and a TEXT link where you can download your converted file from Copy { \"uri\":\"https://leaf-isoxml.s3-us-west-2.amazonaws.com/output/3e1291e4-3026-4357-8bff-0e24feb79602.xml\" } This endpoint will convert a shapefile to ISOXML to be read by a wide variety of machines. This is commonly used for converting VRT prescription files to a machine readable format. Note that the return is plain text, not json.  "},{"title":"CNHI -> GeoJSON","type":1,"pageTitle":"Converters","url":"docs/500-converter#cnhi---geojson","content":"Send this along with your zipped file PythonBashJavaScript Copy var request = require('request'); var headers = { 'Authorization': 'Bearer YOUR_TOKEN' }; var options = { url: 'https://a.agrigate.io/quickstart/api/files/cnhi', method: 'POST', headers: headers }; function callback(error, response, body) { if (!error && response.statusCode == 200) { console.log(body); } } request(options, callback); Returns status 200 and a link where you can download your converted file from Copy { \"uri\":\"https://cnhi-adapt-dev.s3-us-west-2.amazonaws.com/output/3190d2c5-1948-4621-92c5-6bb5c5d36ad1.json.gz\" } This endpoint will convert a CNHi .CN1 file to Leaf's geojson data model. To use, simply upload a zipped .CN1 folder.  "},{"title":"Trimble -> GeoJSON","type":1,"pageTitle":"Converters","url":"docs/500-converter#trimble---geojson","content":"Send this along with your zipped file PythonBashJavaScript Copy var request = require('request'); var headers = { 'Authorization': 'Bearer YOUR_TOKEN' }; var options = { url: 'https://a.agrigate.io/quickstart/api/files/trimble', method: 'POST', headers: headers }; function callback(error, response, body) { if (!error && response.statusCode == 200) { console.log(body); } } request(options, callback); Returns status 200 and a link where you can download your converted file from Copy { \"uri\":\"https://trimble-adapt-dev.s3-us-west-2.amazonaws.com/output/7fc72a96-86f6-4568-b730-a581f883509a.json.gz\" } This endpoint will convert a Trimble file to Leaf's geojson data model. To use, simply upload a zipped Trimble folder.  "},{"title":"Shapefile -> GeoJSON","type":1,"pageTitle":"Converters","url":"docs/500-converter#shapefile---geojson","content":"Send this along with your zipped file PythonBashJavaScript Copy var request = require('request'); var headers = { 'Authorization': 'Bearer YOUR_TOKEN' }; var options = { url: 'https://a.agrigate.io/quickstart/api/converters/shapefile/geojson', method: 'POST', headers: headers }; function callback(error, response, body) { if (!error && response.statusCode == 200) { console.log(body); } } request(options, callback); Returns status 200 and a TEXT link where you can download your converted (json) file from Copy { \"uri\": \"https://converter-prod-conversionsbucket-somerandomstring.s3-us-west-2.amazonaws.com/somerandomstring.json\" } The input file must be a zip file. That is done because shapefile is a multi file standard. It is usually a set of 4 files: .dbf, .prj, .shp and .shx. The output file will be a GeoJSON file.  "},{"title":"GeoJSON -> Shapefile","type":1,"pageTitle":"Converters","url":"docs/500-converter#geojson---shapefile","content":"Send this along with your (Geo)JSON PythonBashJavaScript Copy var request = require('request'); var headers = { 'Authorization': 'Bearer YOUR_TOKEN' }; var options = { url: 'https://a.agrigate.io/quickstart/api/converters/geojson/shapefile/', method: 'POST', headers: headers }; function callback(error, response, body) { if (!error && response.statusCode == 200) { console.log(body); } } request(options, callback); Returns status 200 and a TEXT link where you can download your converted file from Copy { \"uri\": \"https://converter-prod-conversionsbucket-somerandomstring.s3-us-west-2.amazonaws.com/somerandomstring.zip\" } The input file must be a .json GeoJSON file The output file will be a zipped file.  "},{"title":"Satellite","type":0,"sectionRef":"#","url":"docs/502-satellite","content":"","keywords":""},{"title":"About","type":1,"pageTitle":"Satellite","url":"docs/502-satellite#about","content":"Our API returns processed, cropped, and color-corrected RGB and NDVI images.  All HTTP methods should be prepended by this service's endpoint: Copy https://a.agrigate.io/services/satellite/api This service has the following endpoints available: Copy GET /fields GET /fields/{id} GET /fields/{id}/processes POST /fields PUT /fields/{id} DELETE /fields/{id}  "},{"title":"Endpoints","type":1,"pageTitle":"Satellite","url":"docs/502-satellite#endpoints","content":""},{"title":"GET /fields","type":1,"pageTitle":"Satellite","url":"docs/502-satellite#get-fields","content":"Returns paged results for all fields registered. It returns a list of JSON objects like so: Copy [ { \"externalId\":\"your field id\", \"geometry\":{ \"type\":\"MultiPolygon\", \"coordinates\":[...] } }, # etc... ] externalId: external ID used in the field's registrationgeometry: a valid MultiPolygon GeoJSON object with the geometry of the field JavaScriptPythonBash Copy const axios =require('axios') constTOKEN='YOUR_TOKEN' const endpoint ='https://a.agrigate.io/services/satellite/api/fields' const headers ={'Authorization':`Bearer ${TOKEN}`} axios.get(endpoint,{ headers }) .then(res=>console.log(res.data)) .catch(console.error)  "},{"title":"GET /fields/{id}","type":1,"pageTitle":"Satellite","url":"docs/502-satellite#get-fieldsid","content":"Fetches a field entry based on its external id. It returns a single JSON object with the following entries (like each item fromGET /fields results): Copy { \"externalId\":\"your field id\", \"geometry\":{ \"type\":\"MultiPolygon\", \"coordinates\":[...] } } id: external ID used in the field's registrationgeometry: a valid MultiPolygon GeoJSON object with the geometry of the field JavaScriptPythonBash Copy const axios =require('axios') constTOKEN='YOUR_TOKEN' const endpoint ='https://a.agrigate.io/services/satellite/api/fields/YOUR_ID' const headers ={'Authorization':`Bearer ${TOKEN}`} axios.get(endpoint,{ headers }) .then(res=>console.log(res.data)) .catch(console.error)  "},{"title":"GET /fields/{id}/processes","type":1,"pageTitle":"Satellite","url":"docs/502-satellite#get-fieldsidprocesses","content":"Returns all processes already handled by our service. A process is created by our servers whenever there is a new satellite image that intersects with one of your registered fields. This endpoint is used to access all images that each process generates. The returned payload is like so: Copy [ { \"date\":\"2020-06-03T19:03:57.882Z\", \"clouds\":0, \"bucketName\":\"sentinel-s2-l1c\", \"bucketKey\":\"tiles/10/S/FH/2020/6/3/0\", \"bucketRegion\":\"eu-central-1\", \"status\":\"SUCCESS\", \"coverage\":100, \"images\":[ { \"url\":\"url.to.your.image.tif\", \"type\":\"tif\", \"resolution\":20 }, # etc... ] }, # etc... ] date: the date of the satellite imageclouds: cloud coverage percentage of the field, from 0 to 100bucketName: name of Sentinel's bucket where the original tile is. Usuallysentinel-s2-l1cbucketRegion: AWS region of original image's bucket. Usually eu-central-1bucketKey: base path of original satellite imagestatus: status of the process. It will be either SUCCESS or FAILUREcoverage: data coverage percentage of the field, from 0 to 100images: each image in this list will have the following data: url: URL of the imagetype: the type of the image. One of tif, ndvi, png andtif_colorizedresolution: resolution, in meters, of the image. See table below Usually, we generate a total of 17 images for each intersected field. A GeoTiff for each band from Sentinel; some utility images as well, RGB and NDVI. The following table shows all the images with its resolutions and types: Name\tResolution\tTypeB01.tif\t60 meters\ttif B02.tif\t10\ttif B03.tif\t10\ttif B04.tif\t10\ttif B05.tif\t20\ttif B06.tif\t20\ttif B07.tif\t20\ttif B08.tif\t10\ttif B09.tif\t60\ttif B10.tif\t60\ttif B11.tif\t20\ttif B12.tif\t20\ttif NDVI.png\tNULL\tpng NDVI.tif\t10\tndvi NDVI_color.tif\t10\ttif_colorized RGB.png\tNULL\tpng RGB.tif\t10\ttif_colorized PNG files do not have resolution because they are scaled up by 800%, so each pixel does not represent the correct size anymore. We generate a colorized NDVI_color.tif using a custom built color ramp. See the image below. If you want to use your own ramp, we recommend using NDVI.tif, which is a pre calculated NDVI file. You can import it into any GIS software, like QGis, and use it as you please.  JavaScriptPythonBash Copy const axios =require('axios') constTOKEN='YOUR_TOKEN' let endpoint ='https://a.agrigate.io/services/satellite/api'+ '/fields/YOUR_ID/processes' const headers ={'Authorization':`Bearer ${TOKEN}`} axios.get(endpoint,{ headers }) .then(res=>console.log(res.data)) .catch(console.error)  "},{"title":"POST /fields","type":1,"pageTitle":"Satellite","url":"docs/502-satellite#post-fields","content":"Creates a new field entry in the database. A field will start to be monitored as soon as it is added to our database. It will be continuously monitored for as long as it is in there. If you want to stop this process, you should remove the field from the database entirely. Use a DELETE HTTP request. caution Note that the field deletion cascades to all other tables. Meaning that all processed images will be lost. Payload# The payload of this object should be like the following: Copy { \"externalId\":\"your field id\", \"geometry\":{ \"type\":\"MultiPolygon\", \"coordinates\":[...] } } externalId: external ID used in the field's registrationgeometry: a valid MultiPolygon GeoJSON object with the geometry of the field There are some limitations regarding the geometry of the field. It cannot be bigger than 50 million square meters and it cannot have a perimeter bigger than ~28 thousand meters. JavaScriptPythonBash Copy const axios =require('axios') constTOKEN='YOUR_TOKEN' let endpoint ='https://a.agrigate.io/services/satellite/api/fields' const headers ={'Authorization':`Bearer ${TOKEN}`} const data ={/* Your payload */} axios.post(endpoint,{ headers, data }) .then(res=>console.log(res.data)) .catch(console.error)  "},{"title":"PUT /fields/{id}","type":1,"pageTitle":"Satellite","url":"docs/502-satellite#put-fieldsid","content":"Endpoint used to update the geometry of the field. You cannot update the external id. The payload is a single JSON object with an entry geometry which contains a MultiPolygon GeoJSON object. Again, the new geometry must respect the area and perimeter limits of POST /fields. JavaScriptPythonBash Copy const axios =require('axios') constTOKEN='YOUR_TOKEN' let endpoint ='https://a.agrigate.io/services/satellite/api/fields' const headers ={'Authorization':`Bearer ${TOKEN}`} const data ={/* Your geometry */} axios.post(endpoint,{ headers, data }) .then(res=>console.log(res.data)) .catch(console.error)  "},{"title":"DELETE /fields/{id}","type":1,"pageTitle":"Satellite","url":"docs/502-satellite#delete-fieldsid","content":"Deletes the field from our database. caution Be careful when using this method. It will delete all the processed images from the database as well. JavaScriptPythonBash Copy const axios =require('axios') constTOKEN='YOUR_TOKEN' const client = axios.create({ baseURL:'https://a.agrigate.io', headers:{'Authorization':`Bearer ${TOKEN}`} }) client.delete('/fields/YOUR_ID') .then(res=>console.log(res.statusCode)) .catch(console.error) "},{"title":"Operations","type":0,"sectionRef":"#","url":"docs/501-operations","content":"","keywords":""},{"title":"About","type":1,"pageTitle":"Operations","url":"docs/501-operations#about","content":"All HTTP methods should be prepended by this service's endpoint: Copy https://a.agrigate.io/services/operations/api This service has the following endpoints available: Copy GET /files GET /files/{id} GET /files/{id}/summary GET /files/{id}/images POST /files POST /files/merge DELETE /files/{id} "},{"title":"Endpoints","type":1,"pageTitle":"Operations","url":"docs/501-operations#endpoints","content":"Here we list all the available endpoints from this microservice. For easily testing it, we recomend to see our Postman collection. "},{"title":"GET /files","type":1,"pageTitle":"Operations","url":"docs/501-operations#get-files","content":"Gets a paged list of files that belong to the current logged in user. It is possible to filter the results by passing some query parameters. They are listed below. userId, only matches files from this userprovider, filter by the provider. Currently we support the following providers: CNHI, JohnDeere, Trimble and ClimateFieldViewstatus, each file can be on a different step of our processing pipeline. You can match each step of the process by passing one of the following: EMPTY,DOWNLOADED, CONVERTED, FAILED, GENERATED_GEOJSON,GENERATED_STANDARD_GEOJSON, GENERATED_PNGS, GENERATED_SUMMARY,SENT_TO_MERGEfileOrigin, files have differnte origins in our services. You can filter by its origin using one of the following: POOLED, AUTOMERGED, MERGED,UPLOADEDcreatedTime, as ISO 8601 date to filter by the file's creation timeconvertedTime, as ISO 8601 date to filter by the time the files has finished convertingoperationStart, as ISO 8601 date to filter by the operation's start timeoperationEnd, as ISO 8601 date to filter by the operation's end time You can also pass some parameters used exclusively for paging through results. They are: page, an integer specifying the page being fetchedsize, an integer specifying the size of the page It returns a JSON object like the following: Copy [ { \"id\":\"UUID\", \"fileName\":\"filename.zip\", \"providerFileId\":\"123456789\", \"providerName\":\"CNHI\", \"providerId\":2, \"originalUrl\":\"S3_URL\", \"rawGeojsonUrl\":\"S3_URL\", \"status\":\"FAILED\", \"leafUserId\":\"UUID\", \"apiOwnerUsername\":\"CLIENT\", \"fileType\":\"PRESCRIPTION\", \"convertedTime\":\"2020-04-23T13:56:02.68\", \"createdTime\":\"2020-04-16T21:14:03.518\", \"sizeInBytes\":123456789 }, ... ] JavaScriptPythonBash Copy const axios =require('axios') constTOKEN='YOUR_TOKEN' const endpoint ='https://a.agrigate.io/services/operations/api/files' const headers ={'Authorization':`Bearer ${TOKEN}`} axios.get(endpoint,{ headers }) .then(res=>console.log(res.data)) .catch(console.error) "},{"title":"GET files/{id}","type":1,"pageTitle":"Operations","url":"docs/501-operations#get-filesid","content":"Gets a single file by its id. Returns a single JSON object: Copy { \"apiOwnerUsername\":\"string\", \"convertedTime\":\"2020-04-29T20:13:42.811Z\", \"createdTime\":\"2020-04-29T20:13:42.811Z\", \"endTime\":\"2020-04-29T20:13:42.811Z\", \"fileFormat\":\"string\", \"fileName\":\"string\", \"fileType\":\"string\", \"id\":\"UUID\", \"leafUserId\":\"UUID\", \"originalUrl\":\"string\", \"pngUrl\":\"string\", \"providerFieldId\":\"string\", \"providerFileId\":\"string\", \"providerId\":0, \"providerName\":\"string\", \"rawGeojsonUrl\":\"string\", \"sizeInBytes\":0, \"startTime\":\"2020-04-29T20:13:42.812Z\", \"status\":\"string\", \"stdGeojsonUrl\":\"string\" } JavaScriptPythonBash Copy const axios =require('axios') constTOKEN='YOUR_TOKEN' const endpoint ='https://a.agrigate.io/services/operations/api/files/{id}' const headers ={'Authorization':`Bearer ${TOKEN}`} axios.get(endpoint,{ headers }) .then(res=>console.log(res.data)) .catch(console.error) "},{"title":"GET /files/{id}/summary","type":1,"pageTitle":"Operations","url":"docs/501-operations#get-filesidsummary","content":"Gets the summary, if available, for the file id. Returns a single GeoJSON feature containing the convex hull of all operation data and some statistics calculated from it. Copy { \"type\":\"Feature\", \"properties\":{ # these properties and more \"totalDistance\":19194.943013290438, \"startTime\":\"2017-10-27T08:56:52.124000+00:00\", \"endTime\":\"2017-10-27T09:40:46.920000+00:00\", \"operationType\":\"HARVESTED\", \"totalArea\":131638.75702051684 }, \"geometry\":{ \"type\":\"MultiPolygon\", \"coordinates\":[...] } } JavaScriptPythonBash Copy const axios =require('axios') constTOKEN='YOUR_TOKEN' const endpoint ='https://a.agrigate.io/services/operations/api/files/{id}/summary' const headers ={'Authorization':`Bearer ${TOKEN}`} axios.get(endpoint,{ headers }) .then(res=>console.log(res.data)) .catch(console.error) "},{"title":"GET /files/{id}/images","type":1,"pageTitle":"Operations","url":"docs/501-operations#get-filesidimages","content":"Gets a list of PNG images generated from the operation's file properties. Returns a JSON list of the following format: Copy [ { \"property\":\"elevation\", \"ramp\":{ \"0%\":[200,0,0], \"35%\":[255,40,0], \"45%\":[255,150,0], \"55%\":[255,240,0], \"65%\":[0,230,0], \"75%\":[0,190,0], \"100%\":[0,130,0], \"nv\":[0,0,0,0] }, \"url\":\"string\" }, ... ] The property refers to the property extracted from files' data to generate the image. In the example above, the image would represent the elevation. The ramp is the color ramp used to generate the image. The percentages correspond to the minimun (0%) and maximum (100%) values in the image. The listed values corresponde to RGB values used. The nv refers to no value. It is used internally to make the image transparent on places without data. Currently, this ramp is the same of all images processed. JavaScriptPythonBash Copy const axios =require('axios') constTOKEN='YOUR_TOKEN' const endpoint ='https://a.agrigate.io/services/operations/api/files/{id}/images' const headers ={'Authorization':`Bearer ${TOKEN}`} axios.get(endpoint,{ headers }) .then(res=>console.log(res.data)) .catch(console.error) "},{"title":"POST /files","type":1,"pageTitle":"Operations","url":"docs/501-operations#post-files","content":"Posts/creates a new file in our server. This endpoint receives three query parameters. A leafUserId, fileFormat andprovider. The fileFormat must be one of the following: Copy ADAPTADM CN1 DATCLIMATE GEOJSON ISO11783 SHAPEFILE TRIMBLE Provider must be one of the following: Copy ClimateFieldView CNHI JohnDeere Leaf Trimble Returns a single JSON object: Copy { \"message\":\"Your file is being processed and will be available in a few minutes\", \"id\":\"id\" } JavaScriptPythonBash Copy const axios =require('axios') constTOKEN='YOUR_TOKEN' const endpoint ='https://a.agrigate.io/services/operations/api/files' const headers ={ 'Authorization':`Bearer ${TOKEN}` 'Content-Type':'multipart/form-data' } const params ={ fileFormat:'SHAPEFILE', provider:'JohnDeere', leafUserId:'id' } const form =newFormData() form.append('file','shapefile.zip') axios.post(endpoint, form,{ headers, params }) .then(res=>console.log(res.data)) .catch(console.error) "},{"title":"POST /files/merge","type":1,"pageTitle":"Operations","url":"docs/501-operations#post-filesmerge","content":"Posts a merge operation to our server. A merge operation is performed asynchronously. This call will return immediately with the newly created file entry, but at this point the file is not already processed and available. You will need to make new GET /files request for the new id and check the status. A status value of CONVERTED means the file is done merging. A merge process has some limitations however. The files passed must belong to the same user, be of the same operation type and have the status as CONVERTED. If any of those filters fail, the endpoint will result in HTTP 400 error. It receives a single JSON object with the ids entry. Example: Copy { \"ids\":[\"id1\",\"id2\",\"so on\"] } Returns a single JSON object: Copy { \"id\":\"id\", \"status\":\"SENT_TO_MERGE\" } JavaScriptPythonBash Copy const axios =require('axios') constTOKEN='YOUR_TOKEN' const endpoint ='https://a.agrigate.io/services/operations/api/files/merge' const headers ={'Authorization':`Bearer ${TOKEN}`} const data ={ ids:['id1','id2']} axios.post(endpoint,{ headers, data }) .then(res=>console.log(res.data)) .catch(console.error) "}]